{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nick088Official/Face-Fusion-Headless-Colab/blob/main/Face_Fusion_Headless_No_UI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgVreYca3LcQ"
      },
      "source": [
        "# **FACE FUSION MANUAL 2.3.0**\n",
        "\n",
        "DeepFake AI Tool\n",
        "\n",
        "Google Colab Notebook Made By **Nick088**:\n",
        "- [Youtube](https://www.youtube.com/channel/@Nick088Official)\n",
        "- [TikTok](https://www.tiktok.com/@forgotforever)\n",
        "- [Reddit](reddit.com/user/Nick088Real)\n",
        "- [Twitter](https://twitter.com/Nick088Official)\n",
        "- [Discord](https://discord.com/channels/@me/911742715019001897)\n",
        "\n",
        "##GUIDE:\n",
        "1. Run Install Face Fusion and wait until it finishes (at the end a red message appears telling you to restart the runtime, don't do it).\n",
        "\n",
        "2. On the left of the page click on the folder icon which will show you the File section, right click on the y8e23w6s folder (Called like that for bypassing the colab ban) and load the photo used as a reference point (called Source) and the video or photo whose face you want to change (called Target).\n",
        "\n",
        "3. Wait until the Target and Source files are loaded, and then in the Run Face Fusion code block, next to -t in the \"\" insert the name of the Video or the Target Photo (also insert the extension of your file, e.g. source.jpeg, target.mp4, target.png, output.mp4, output.jpg), for -s put the name of the photo Source, and for -o insert the name you want to give to the final output, finally run the code (Be careful to make some links every now and then so it doesn't disconnect due to inactivity, you could also check https://rentry.org/colab_workarounds).\n",
        "\n",
        "4. **(OPTIONAL)** You can put additional options in the code block before running it, all options are in the colab with explanations.\n",
        "\n",
        "5. **(OPTIONAL)** If the process is too slow you can speed it up at the cost of losing some quality of the output, by removing “face_enhancer” and “frame_enhancer” at the end of the code block,after frame_processors, before running it.\n",
        "\n",
        "6. **(OPTIONAL)** If the process is too slow, you can split the Target video into videos of 1 minute each, and run the process again for each video, then finally link them all together by placing them on any free editing app like Capcut\n",
        "\n",
        "7. After the output is completed, click the 3 dots on it and click download, don't close anything until it finishes downloading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZlrnUA3i3gMB",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title INSTALL FACE FUSION\n",
        "#@markdown Run this and wait (at the end a red message appears telling you to restart the runtime, don't do it)\n",
        "!git clone http://tinyurl.com/y8e23w6s --branch 2.3.0 --single-branch\n",
        "!pip install onnxruntime-gpu && pip install -r /content/y8e23w6s/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Mount Google Drive\n",
        "from google.colab import drive\n",
        "import shutil\n",
        "drive.mount('/content/drive')\n",
        "!mkdir /content/drive/MyDrive/FaceFusion/"
      ],
      "metadata": {
        "cellView": "form",
        "id": "pL88z9EXUJOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsfWtUCSGrrl"
      },
      "source": [
        "**RUN FACE FUSION**\n",
        "\n",
        "In the following code block below all this text, there are already some useful options choosen, here you can also see all options you can add to the code below before running it:\n",
        "```\n",
        "options:\n",
        "  -s SOURCE_PATHS, --source SOURCE_PATHS                                                                             select a source image\n",
        "  -t TARGET_PATH, --target TARGET_PATH                                                                               select a target image or video\n",
        "  -o OUTPUT_PATH, --output OUTPUT_PATH                                                                               specify the output file or directory\n",
        "\n",
        "misc:\n",
        "  --skip-download                                                                                                    omit automate downloads and lookups\n",
        "  --headless                                                                                                         run the program in headless mode (NO UI)\n",
        "\n",
        "execution:\n",
        "  --execution-providers EXECUTION_PROVIDERS [EXECUTION_PROVIDERS ...]                                                choose from the available execution providers (choices: cpu, azure)\n",
        "  --execution-thread-count [1-128]                                                                                   specify the number of execution threads\n",
        "  --execution-queue-count [1-32]                                                                                     specify the number of execution queries\n",
        "\n",
        "face analyser:\n",
        "  --face-analyser-order {left-right,right-left,top-bottom,bottom-top,small-large,large-small,best-worst,worst-best}  specify the order used for the face analyser\n",
        "  --face-analyser-age {child,teen,adult,senior}                                                                      specify the age used for the face analyser\n",
        "  --face-analyser-gender {male,female}                                                                               specify the gender used for the face analyser\n",
        "  --face-detector-model {retinaface,yunet}                                                                           specify the model used for the face detector\n",
        "  --face-detector-size {160x160,320x320,480x480,512x512,640x640,768x768,960x960,1024x1024}                           specify the size threshold used for the face detector\n",
        "  --face-detector-score [0.0-1.0]                                                                                    specify the score threshold used for the face detector\n",
        "\n",
        "face selector:\n",
        "  --face-selector-mode {reference,one,many}                                                                          specify the mode for the face selector\n",
        "  --reference-face-position REFERENCE_FACE_POSITION                                                                  specify the position of the reference face\n",
        "  --reference-face-distance [0.0-1.5]                                                                                specify the distance between the reference face and the target face\n",
        "  --reference-frame-number REFERENCE_FRAME_NUMBER                                                                    specify the number of the reference frame\n",
        "\n",
        "face mask:\n",
        "  --face-mask-types FACE_MASK_TYPES [FACE_MASK_TYPES ...]                                                            choose from the available face mask types (choices: box, occlusion, region)\n",
        "  --face-mask-blur [0.0-1.0]                                                                                         specify the blur amount for face mask\n",
        "  --face-mask-padding FACE_MASK_PADDING [FACE_MASK_PADDING ...]                                                      specify the face mask padding (top, right, bottom, left) in percent\n",
        "  --face-mask-regions FACE_MASK_REGIONS [FACE_MASK_REGIONS ...]                                                      choose from the available face mask regions (choices: skin, left-eyebrow, right-eyebrow, left-eye, right-eye, eye-glasses, nose, mouth, upper-lip, lower-lip)\n",
        "\n",
        "frame extraction:\n",
        "  --trim-frame-start TRIM_FRAME_START                                                                                specify the start frame for extraction\n",
        "  --trim-frame-end TRIM_FRAME_END                                                                                    specify the end frame for extraction\n",
        "  --temp-frame-format {jpg,png}                                                                                      specify the image format used for frame extraction\n",
        "  --temp-frame-quality [0-100]                                                                                       specify the image quality used for frame extraction\n",
        "  --keep-temp                                                                                                        keep the temporary resources after processing\n",
        "\n",
        "output creation:\n",
        "  --output-image-quality [0-100]                                                                                     specify the quality used for the output image\n",
        "  --output-video-encoder {libx264,libx265,libvpx-vp9,h264_nvenc,hevc_nvenc}                                          specify the encoder used for the output video\n",
        "  --output-video-preset {ultrafast,superfast,veryfast,faster,fast,medium,slow,slower,veryslow}                       balance fast video processing and video file size\n",
        "  --output-video-quality [0-100]                                                                                     specify the quality used for the output video\n",
        "  --output-video-resolution OUTPUT_VIDEO_RESOLUTION                                                                  specify the video output resolution based on the target video\n",
        "  --output-video-fps OUTPUT_VIDEO_FPS                                                                                specify the video output fps based on the target video\n",
        "  --skip-audio                                                                                                       omit audio from the target\n",
        "\n",
        "frame processors:\n",
        "  --frame-processors FRAME_PROCESSORS [FRAME_PROCESSORS ...]                                                         choose from the available frame processors (choices: face_debugger, face_enhancer, face_swapper, frame_enhancer, ...)\n",
        "  --face-debugger-items FACE_DEBUGGER_ITEMS [FACE_DEBUGGER_ITEMS ...]                                                specify the face debugger items (choices: bbox, kps, face-mask, score)\n",
        "  --face-enhancer-model {codeformer,gfpgan_1.2,gfpgan_1.3,gfpgan_1.4,gpen_bfr_256,gpen_bfr_512,restoreformer}        choose the model for the frame processor\n",
        "  --face-enhancer-blend [0-100]                                                                                      specify the blend amount for the frame processor\n",
        "  --face-swapper-model {blendswap_256,inswapper_128,inswapper_128_fp16,simswap_256,simswap_512_unofficial}           choose the model for the frame processor\n",
        "  --frame-enhancer-model {real_esrgan_x2plus,real_esrgan_x4plus,real_esrnet_x4plus}                                  choose the model for the frame processor\n",
        "  --frame-enhancer-blend [0-100]                                                                                     specify the blend amount for the frame processor\n",
        "  --lip-syncer-model {wav2lip_gan}                                                                                   choose the model responsible for syncing the lips\n",
        "  ```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YVHiNI-bb6IA"
      },
      "outputs": [],
      "source": [
        "%cd \"/content/y8e23w6s/\"\n",
        "!python run.py --headless -t \"Target.mp4\" -s \"Source.jpg\" -o \"/content/output.mp4\" --face-selector-mode many --temp-frame-quality 100 --output-video-quality 100 --output-image-quality 100 --execution-providers azure cpu --execution-thread-count 8 --execution-queue-count 1 --face-enhancer-blend 100 --frame-enhancer-blend 100 --lip-syncer-model wav2lip_gan --frame-processors face_swapper face_enhancer frame_enhancer"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}